{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11451444,"sourceType":"datasetVersion","datasetId":7174884}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# importing libraries\nimport os\nimport numpy as np\nimport random\nimport torch\nimport pytorch_lightning as pl\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom PIL import Image\nimport wandb\nfrom pytorch_lightning.loggers.wandb import WandbLogger\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\nimport torch.nn.functional as F\nimport gc\nimport matplotlib.pyplot as plt\nfrom io import BytesIO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:05:32.355067Z","iopub.execute_input":"2025-04-19T16:05:32.355330Z","iopub.status.idle":"2025-04-19T16:05:49.457392Z","shell.execute_reply.started":"2025-04-19T16:05:32.355310Z","shell.execute_reply":"2025-04-19T16:05:49.456847Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb_key\")\n\nos.environ['WANDB_API_KEY'] = secret_value_0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:05:49.458336Z","iopub.execute_input":"2025-04-19T16:05:49.458551Z","iopub.status.idle":"2025-04-19T16:05:49.553834Z","shell.execute_reply.started":"2025-04-19T16:05:49.458533Z","shell.execute_reply":"2025-04-19T16:05:49.553308Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Custom Dataset for iNaturalist\n\nclass iNaturalistDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        self.class_names = sorted(os.listdir(data_dir))\n\n        # storing all labels, iamge paths\n        for label, class_name in enumerate(self.class_names):\n            class_dir = os.path.join(data_dir, class_name)\n            for image_name in os.listdir(class_dir):\n                self.image_paths.append(os.path.join(class_dir, image_name))\n                self.labels.append(label)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    # get a particular image\n    def __getitem__(self, idx):\n        image = Image.open(self.image_paths[idx]).convert('RGB')\n        label = self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:05:52.545429Z","iopub.execute_input":"2025-04-19T16:05:52.545925Z","iopub.status.idle":"2025-04-19T16:05:52.551364Z","shell.execute_reply.started":"2025-04-19T16:05:52.545899Z","shell.execute_reply":"2025-04-19T16:05:52.550833Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Data Preprocessing and Augmentation\ndef get_transforms(data_augmentation=True):\n    if data_augmentation:\n        return transforms.Compose([\n            transforms.Resize(256),\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(15),\n            transforms.ColorJitter(brightness=0.1,contrast=0.1,saturation=0.1,hue=0.05),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n    else:\n        return transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:05:53.654210Z","iopub.execute_input":"2025-04-19T16:05:53.654758Z","iopub.status.idle":"2025-04-19T16:05:53.659352Z","shell.execute_reply.started":"2025-04-19T16:05:53.654734Z","shell.execute_reply":"2025-04-19T16:05:53.658662Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class SimpleCNN(pl.LightningModule):\n    def __init__(self, convFilters, filterSizes, activationFn, useBatchNorm, dropoutRate,\n                 optimizerType, learningRate, weightDecay, denseFeatures, numClasses=10):\n        super().__init__()\n        self.save_hyperparameters()  # Save hyperparameters for easy access and logging\n\n        # Define the loss function here\n        self.lossFn = nn.CrossEntropyLoss()\n\n        self.train_losses = []\n        self.train_accuracies = []\n        self.val_losses = []\n        self.val_accuracies = []\n        self.test_accuracy=[]\n        self.test_loss=[]\n        \n        self.convBlocks = nn.ModuleList() \n        in_channels = 3  \n\n        # Construct convolutional blocks based on given filters and kernel sizes\n        for out_channels, k in zip(convFilters, filterSizes):\n            layers = [nn.Conv2d(in_channels, out_channels, kernel_size=k, stride=1, padding=k // 2)]\n            if useBatchNorm:\n                layers.append(nn.BatchNorm2d(out_channels))  # Add BatchNorm if enabled\n            layers.append(activationFn())  # Add activation function (ReLU, GELU, etc.)\n            layers.append(nn.MaxPool2d(2)) \n            if dropoutRate > 0:\n                layers.append(nn.Dropout2d(dropoutRate))\n            self.convBlocks.append(nn.Sequential(*layers)) \n            in_channels = out_channels  # Set input channels for next block\n\n        with torch.no_grad():\n            dummy_input = torch.zeros(1, 3, 224, 224)\n            for block in self.convBlocks:\n                dummy_input = block(dummy_input)\n            self.flattened_size = dummy_input.view(1, -1).shape[1]  \n        # Fully connected (dense) layer\n        self.fc = nn.Linear(self.flattened_size, denseFeatures)\n        self.fc_activation = activationFn()  # Activation after dense layer\n        self.dropout = nn.Dropout(dropoutRate) if dropoutRate > 0 else nn.Identity()  # Optional dropout\n        self.outputLayer = nn.Linear(denseFeatures, numClasses)  # Final classification layer\n\n        # Cross-entropy loss for multi-class classification\n        self.lossFn = nn.CrossEntropyLoss()\n\n    def forward(self, x):\n        # Pass input through convolutional blocks\n        for block in self.convBlocks:\n            x = block(x)\n        x = torch.flatten(x, start_dim=1)  # Flatten for fully connected layer\n        x = self.fc_activation(self.fc(x))  # Apply dense layer and activation\n        x = self.dropout(x)  # Apply dropout (if any)\n        return self.outputLayer(x)  # Output raw class scores (logits)\n        \n    def training_step(self, batch, batchIdx):\n        # Training logic: forward pass + compute loss\n        images, labels = batch\n        logits = self(images)\n        loss = self.lossFn(logits, labels)\n        preds = torch.argmax(logits, dim=1)\n        acc = (preds == labels).float().mean()\n        self.log(\"train_loss\", loss, prog_bar=True)\n        self.log(\"train_accuracy\", acc, prog_bar=True)\n        return {'loss': loss,'acc':acc}\n\n    def validation_step(self, batch, batchIdx):\n        # Validation logic: compute loss and accuracy\n        images, labels = batch\n        logits = self(images)\n        loss = self.lossFn(logits, labels)\n        preds = torch.argmax(logits, dim=1)\n        acc = (preds == labels).float().mean()\n        self.log(\"val_loss\", loss, prog_bar=True)\n        self.log(\"val_accuracy\", acc, prog_bar=True)\n        return {'loss': loss,'acc':acc}\n\n    def test_step(self, batch, batch_idx):\n        # Validation logic: compute loss and accuracy\n        images, labels = batch\n        logits = self(images)\n        loss = self.lossFn(logits, labels)\n        preds = torch.argmax(logits, dim=1)\n        acc = (preds == labels).float().mean()\n        #storing accuracies to print afterwards\n        self.test_accuracy.append(acc.item())\n        self.test_loss.append(loss.item())\n        self.log(\"test_loss\", loss, prog_bar=True)\n        self.log(\"test_accuracy\", acc, prog_bar=True)\n\n    def on_test_epoch_end(self):\n        #printing Final Test accuracy and loss\n        avg_accuracy = sum(self.test_accuracy) / len(self.test_accuracy)\n        avg_loss = sum(self.test_loss) / len(self.test_loss)\n        print(f\"\\nFinal Test Accuracy: {avg_accuracy:.4f}\")\n        print(f\"Final Test Loss: {avg_loss:.4f}\")\n\n    def evaluate(self, dataloader, stage=\"train\"):\n        self.eval()\n        correct = 0\n        total = 0\n        total_loss = 0.0\n        with torch.no_grad():\n            for x, y in dataloader:\n                x, y = x.to(self.device), y.to(self.device)\n                logits = self(x)\n                loss = F.cross_entropy(logits, y)\n                preds = torch.argmax(logits, dim=1)\n    \n                correct += (preds == y).sum().item()\n                total += y.size(0)\n                total_loss += loss.item() * y.size(0)\n    \n        avg_loss = total_loss / total\n        accuracy = correct / total\n        print(f\"{stage.capitalize()} Accuracy: {accuracy:.4f}, {stage.capitalize()} Loss: {avg_loss:.4f}\")\n\n    \n    # Define optimizer based on provided hyperparameters\n    def configure_optimizers(self):\n        if self.hparams.optimizerType == 'adam':\n            return torch.optim.Adam(self.parameters(), lr=self.hparams.learningRate, weight_decay=self.hparams.weightDecay)\n        elif self.hparams.optimizerType == 'nadam':\n            return torch.optim.NAdam(self.parameters(), lr=self.hparams.learningRate, weight_decay=self.hparams.weightDecay)\n        elif self.hparams.optimizerType == 'rmsprop':\n            return torch.optim.RMSprop(self.parameters(), lr=self.hparams.learningRate, weight_decay=self.hparams.weightDecay)\n        else:\n            raise ValueError(f\"{self.hparams.optimizerType} optimizer not implemented\")  # Handle unknown optimizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:19:41.143629Z","iopub.execute_input":"2025-04-19T16:19:41.143987Z","iopub.status.idle":"2025-04-19T16:19:41.161675Z","shell.execute_reply.started":"2025-04-19T16:19:41.143957Z","shell.execute_reply":"2025-04-19T16:19:41.161072Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def load_data(batch_size, data_augmentation=True):\n    \"\"\"\n    Load and prepare the iNaturalist dataset with data augmentation and parallelized data loading.\n    \"\"\"\n    # Get image transformation pipeline\n    transform = get_transforms(data_augmentation)\n\n    # Load dataset\n    dataset = iNaturalistDataset('/kaggle/input/inaturalist_12K/train', transform)\n\n    # Split into training (80%) and validation (20%) sets\n    train_size = int(0.8 * len(dataset))\n    val_size = len(dataset) - train_size\n    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n    num_workers=0\n    if torch.cuda.is_available():\n        num_workers = min(4, os.cpu_count())\n    else:\n        num_workers = 0\n    pin_memory = torch.cuda.is_available()\n\n    train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=num_workers,pin_memory=pin_memory)\n    val_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=False,num_workers=num_workers,pin_memory=pin_memory)\n\n    return train_loader, val_loader\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:06:00.712045Z","iopub.execute_input":"2025-04-19T16:06:00.712569Z","iopub.status.idle":"2025-04-19T16:06:00.717850Z","shell.execute_reply.started":"2025-04-19T16:06:00.712543Z","shell.execute_reply":"2025-04-19T16:06:00.716949Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"activation_functions = {\n    'relu': torch.nn.ReLU,\n    'gelu': torch.nn.GELU,\n    'silu': torch.nn.SiLU,\n    'mish': None  # Special case for Mish (since it's not built-in)\n}\n\ndef get_activation_fn(config_activation_fn):\n    # Handled 'mish' as a special case (it's not a built-in PyTorch activation function)\n    if config_activation_fn.lower() == 'mish':\n        class Mish(torch.nn.Module):\n            def forward(self, x):\n                return x * torch.tanh(torch.nn.functional.softplus(x))\n        return Mish\n    # Otherwise, used the dictionary for built-in activations\n    elif config_activation_fn.lower() in activation_functions:\n        return activation_functions[config_activation_fn.lower()]\n    else:\n        raise ValueError(f\"Activation function {config_activation_fn} not recognized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:06:03.253408Z","iopub.execute_input":"2025-04-19T16:06:03.253687Z","iopub.status.idle":"2025-04-19T16:06:03.258792Z","shell.execute_reply.started":"2025-04-19T16:06:03.253666Z","shell.execute_reply":"2025-04-19T16:06:03.258063Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"## running on sample params\n\n# Define hyperparameters\nconvFilters = [256, 128, 64, 32,16]\nfilterSizes = [3, 5, 3, 5, 3]\nactivationFn = get_activation_fn('silu')\nuseBatchNorm = False\ndropoutRate = 0.3\noptimizerType = 'adam'\nlearningRate = 0.0001\nweightDecay = 0\ndenseFeatures = 512\nnumClasses = 10  # Adjust for the number of classes in iNaturalist\nbatch_size = 64  # Batch size for data loading\n\n# Initialize the model\nmodel = SimpleCNN(convFilters=convFilters,filterSizes=filterSizes,activationFn=activationFn,useBatchNorm=useBatchNorm,dropoutRate=dropoutRate,\n                  optimizerType=optimizerType,learningRate=learningRate,weightDecay=weightDecay,denseFeatures=denseFeatures,numClasses=numClasses)\n\n# Load data\ntrain_loader, val_loader = load_data(batch_size, data_augmentation=True)\n\n# --- EARLY STOPPING ---\nearly_stop_callback = EarlyStopping(\n    monitor=\"val_acc\",\n    patience=5,\n    verbose=True,\n    mode=\"max\"\n)\n\ndevices = 0\n# Set up the PyTorch Lightning Trainer\nif torch.cuda.is_available():\n    accelerator = \"gpu\"\n    devices     = torch.cuda.device_count() \nelse:\n    accelerator = \"cpu\"\n    devices     = 1 \n\ntrainer = pl.Trainer(precision='16-mixed',max_epochs = 1,accelerator = accelerator,devices =devices,\n                     callbacks=[early_stop_callback])\n# Train the model\ntrainer.fit(model, train_loader, val_loader)\ntrain_metrics = trainer.callback_metrics\nval_metrics = trainer.validate(model, dataloaders=val_loader, verbose=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:06:07.057945Z","iopub.execute_input":"2025-04-19T16:06:07.058225Z","iopub.status.idle":"2025-04-19T16:06:07.062328Z","shell.execute_reply.started":"2025-04-19T16:06:07.058203Z","shell.execute_reply":"2025-04-19T16:06:07.061546Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Hyperparameter sweep configuration\nsweep_config = {\n    'method': 'random',\n    'metric': {'name': 'val_accuracy', 'goal': 'maximize'},\n    'parameters': {\n        # Convolutional layer configurations\n        'convFilters': {'values': [[32]*5, [16, 32, 64, 128, 256], [256, 128, 64, 32,16], [128, 128, 64, 64, 32]]},\n        'filterSizes': {'values': [[3, 3, 3, 3, 3], [5, 5, 5, 5, 5], [3, 5, 3, 5, 3]]},\n        'useBatchNorm': {'values': [True, False]},\n        'dropoutRate': {'values': [0.2, 0.3]},\n        'optimizerType': {'values': ['adam', 'nadam', 'rmsprop']},\n        'learningRate': {'values': [1e-2, 1e-3, 1e-4]},\n        'weightDecay': {'values': [0.0, 0.0005, 0.005]},\n        'activationFn': {'values': ['relu', 'gelu', 'silu', 'mish']},\n        'dataAugmentation': {'values': [True, False]},\n        'denseFeatures': {'values': [ 256, 512, 1024]},\n        'batchSize': {'values': [32, 64]},\n        'maxEpochs': {'values': [10]}\n    }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:06:13.898834Z","iopub.execute_input":"2025-04-19T16:06:13.899117Z","iopub.status.idle":"2025-04-19T16:06:13.904699Z","shell.execute_reply.started":"2025-04-19T16:06:13.899095Z","shell.execute_reply":"2025-04-19T16:06:13.904037Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Divding Hyperparameters into 2 parts \n\nPhase 1: Model Architecture\nFocus on the structure of the network and the architectural choices (convFilters, filterSizes, activationFn). These choices directly impact model performance and can have a significant effect on training speed and accuracy.\n\nPhase 2: Training Hyperparameters\nAfter deciding on the architecture, fine-tune the training parameters (optimizer, learning rate, batch size, etc.) that affect the convergence and performance stability.","metadata":{}},{"cell_type":"code","source":"# Phase 1 Sweep Config (Model Architecture)\nsweep_config_phase1 = {\n    'method': 'random',  # Use random search for broad exploration\n    'metric': {'name': 'val_accuracy', 'goal': 'maximize'},\n    'parameters': {\n        # Convolutional layer configurations (focusing on architecture-related choices)\n        'convFilters': {'values': [[32]*5, [16,32, 64, 128, 256], [256, 128, 64, 32,16], [128, 128, 64, 64, 32]]},\n        'filterSizes': {'values': [[3, 3, 3, 3, 3], [5, 5, 5, 5, 5], [3, 5, 3, 5, 3]]},\n        'activationFn': {'values': ['relu', 'gelu', 'silu', 'mish']},\n        'useBatchNorm': {'values': [True, False]},  # To explore if batch normalization improves the performance\n        'dropoutRate': {'values': [0.2, 0.3]},  # To check the impact of dropout\n        'dataAugmentation': {'values': [True, False]},  # Explore data augmentation impact\n        'denseFeatures': {'values': [256, 512, 1024]},  # Exploring different dense layer sizes\n    }\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:06:16.850623Z","iopub.execute_input":"2025-04-19T16:06:16.850988Z","iopub.status.idle":"2025-04-19T16:06:16.856235Z","shell.execute_reply.started":"2025-04-19T16:06:16.850963Z","shell.execute_reply":"2025-04-19T16:06:16.855432Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def train_model_phase1():\n    # Clearing memory before starting each run\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    run = wandb.init(project=\"da6401_Assignment2\", config=sweep_config_phase1)\n    config = wandb.config\n\n    # Construct the run name based on phase 1 parameters\n    run_name = f\"activationFn={config['activationFn']}_convFilters={config['convFilters']}_\" \\\n               f\"dataAugmentation={config['dataAugmentation']}_denseFeatures={config['denseFeatures']}_\" \\\n               f\"dropoutRate={config['dropoutRate']}_filterSizes={config['filterSizes']}_\" \\\n               f\"useBatchNorm={config['useBatchNorm']}\"\n\n    run.name = run_name  # Set the run name\n\n    activation_fn = get_activation_fn(config.activationFn)\n\n    # Initialize the model with phase 1-configured parameters\n    model = SimpleCNN(\n        convFilters=config.convFilters,\n        filterSizes=config.filterSizes,\n        activationFn=activation_fn,\n        useBatchNorm=config.useBatchNorm,\n        dropoutRate=config.dropoutRate,\n        optimizerType=\"adam\",\n        learningRate=1e-3,     # Default learning rate for phase 1\n        weightDecay=0.0,       # Default weight decay for phase 1\n        denseFeatures=config.denseFeatures,\n        numClasses=10\n    )\n\n    batch_size = 64\n    maxEpochs=10\n\n    # Load train and validation datasets\n    train_loader, val_loader = load_data(batch_size, config.dataAugmentation)\n    wandb_logger = WandbLogger(log_model=True)\n\n    # Early Stopping (for Phase 1)\n    early_stop_callback = EarlyStopping(\n        monitor=\"val_acc\",\n        patience=3,\n        verbose=True,\n        mode=\"max\",\n        check_on_train_epoch_end=True\n    )\n\n    # Set up PyTorch Lightning Trainer\n    devices = 1\n    if torch.cuda.is_available():\n        accelerator = \"gpu\"\n        devices = torch.cuda.device_count()\n    else:\n        accelerator = \"cpu\"\n        devices = 1\n\n    trainer = pl.Trainer(\n        precision='16-mixed',\n        max_epochs=maxEpochs,\n        accelerator=accelerator,\n        logger=wandb_logger,\n        devices=devices,\n        callbacks=[early_stop_callback]\n    )\n\n    # Train model\n    trainer.fit(model, train_loader, val_loader)\n\n    # Final evaluation\n    train_metrics = trainer.callback_metrics\n    val_metrics = trainer.validate(model, dataloaders=val_loader, verbose=False)\n\n    # Log final metrics for sweep to work\n    wandb.log({\n        \"train_accuracy\": train_metrics[\"train_acc\"].item(),\n        \"train_loss\": train_metrics[\"train_loss\"].item(),\n        \"val_accuracy\": val_metrics[0]['val_acc'],  # Required by sweep\n        \"val_loss\": val_metrics[0]['val_loss']\n    })\n    run.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:06:20.462677Z","iopub.execute_input":"2025-04-19T16:06:20.463241Z","iopub.status.idle":"2025-04-19T16:06:20.470566Z","shell.execute_reply.started":"2025-04-19T16:06:20.463217Z","shell.execute_reply":"2025-04-19T16:06:20.469848Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Run the sweep \nsweep_id = wandb.sweep(sweep_config_phase1, project=\"da6401_Assignment2\")\nwandb.agent(sweep_id, function=train_model_phase1, count=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:06:26.339321Z","iopub.execute_input":"2025-04-19T16:06:26.339609Z","iopub.status.idle":"2025-04-19T16:06:26.343058Z","shell.execute_reply.started":"2025-04-19T16:06:26.339586Z","shell.execute_reply":"2025-04-19T16:06:26.342333Z"},"_kg_hide-input":false},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Phase 2 Sweep Config (Training Hyperparameters)\nsweep_config_phase2 = {\n    'method': 'bayes',\n    'metric': {'name': 'val_accuracy', 'goal': 'maximize'},\n    'parameters': {\n        # Training hyperparameters (fine-tuning the training process)\n        #from phase1\n        'convFilters': {'values': [ [256, 128, 64, 32,16], [128, 128, 64, 64, 32]]},\n        'filterSizes': {'values': [[3, 3, 3, 3, 3], [3, 5, 3, 5, 3]]},\n        'activationFn': {'values': [ 'gelu', 'silu', 'mish']},\n        'dropoutRate': {'values': [0.2, 0.3]},  # To check the impact of dropout\n        'denseFeatures': {'values': [512, 1024]},  # Exploring different dense layer sizes\n        #tuning now\n        'optimizerType': {'values': ['adam', 'nadam', 'rmsprop']},  # Different optimizers\n        'learningRate': {'values': [1e-2, 1e-3, 1e-4]},  # Learning rate exploration\n        'weightDecay': {'values': [0.0, 0.0005, 0.005]},  # Exploring different weight decays\n    }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:06:31.573170Z","iopub.execute_input":"2025-04-19T16:06:31.573621Z","iopub.status.idle":"2025-04-19T16:06:31.578324Z","shell.execute_reply.started":"2025-04-19T16:06:31.573597Z","shell.execute_reply":"2025-04-19T16:06:31.577622Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def train_model_phase2():\n    # Clear out any leftover GPU memory\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    # Start W&B run\n    run = wandb.init(project=\"da6401_Assignment2\", config=sweep_config_phase2)\n    config = wandb.config\n    \n    run_name = (f\"activationFn={config.activationFn}_\"\n        f\"convFilters={'-'.join(map(str, config.convFilters))}_\"\n        f\"filterSizes={'-'.join(map(str, config.filterSizes))}_\"\n        f\"denseFeatures={config.denseFeatures}_\"\n        f\"dropoutRate={config.dropoutRate}_\"\n        f\"useBatchNorm=True_\"  # hardcoded as always true in Phase 2\n        f\"dataAugmentation=False_\"  # hardcoded as always false in Phase 2\n        f\"optimizerType={config.optimizerType}_\"\n        f\"learningRate={config.learningRate}_\"\n        f\"weightDecay={config.weightDecay}\")\n\n    run.name = run_name\n    \n    # Get activation function object from its name\n    activation_fn = get_activation_fn(config.activationFn)\n    \n    # Initialize model using Phase 1 architecture + Phase 2 training params\n    model = SimpleCNN(convFilters    = config.convFilters,\n        filterSizes    = config.filterSizes,\n        activationFn   = activation_fn,\n        useBatchNorm   = True,                # forced ON in Phase 2\n        dropoutRate    = config.dropoutRate,\n        optimizerType  = config.optimizerType,\n        learningRate   = config.learningRate,\n        weightDecay    = config.weightDecay,\n        denseFeatures  = config.denseFeatures,\n        numClasses     = 10)\n    \n    # DataLoaders: augmentation OFF in Phase 2\n    batch_size = 64\n    train_loader, val_loader = load_data(batch_size, data_augmentation=False)\n    wandb_logger = WandbLogger(log_model=True)\n    \n    #  Early stopping\n    early_stop = EarlyStopping(\n        monitor=\"val_accuracy\", patience=5, mode=\"max\", verbose=True,\n        check_on_train_epoch_end=True\n    )\n    \n    #  Trainer\n    trainer = pl.Trainer(\n        precision='16-mixed',\n        max_epochs=10,\n        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n        devices=torch.cuda.device_count() if torch.cuda.is_available() else 1,\n        logger=wandb_logger,\n        callbacks=[early_stop]\n    )\n    \n    #  Fit & validate\n    trainer.fit(model, train_loader, val_loader)\n    train_metrics = trainer.callback_metrics\n    val_metrics   = trainer.validate(model, dataloaders=val_loader, verbose=False)\n    \n    run.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:06:38.753464Z","iopub.execute_input":"2025-04-19T16:06:38.753750Z","iopub.status.idle":"2025-04-19T16:06:38.761027Z","shell.execute_reply.started":"2025-04-19T16:06:38.753726Z","shell.execute_reply":"2025-04-19T16:06:38.760172Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Run the sweep \nsweep_id = wandb.sweep(sweep_config_phase2, project=\"da6401_Assignment2\")\nwandb.agent(sweep_id, function=train_model_phase2, count=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:06:43.442690Z","iopub.execute_input":"2025-04-19T16:06:43.443273Z","iopub.status.idle":"2025-04-19T16:06:43.446313Z","shell.execute_reply.started":"2025-04-19T16:06:43.443248Z","shell.execute_reply":"2025-04-19T16:06:43.445556Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Question 4\n\n# Best hyperparameters (from wandb sweep)\nbestConfig = {\n    'convFilters': [128,128,64,64,32],\n    'filterSizes': [3, 5, 3, 5, 3],\n    'activationFn': 'mish',\n    'useBatchNorm': True,\n    'dropoutRate': 0.2,\n    'optimizerType': 'adam',\n    'learningRate': 0.0001,\n    'weightDecay': 0,\n    'denseFeatures': 512,\n    'numClasses': 10,\n    'dataAugmentation':False,\n    'batchSize' : 64\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:06:51.416773Z","iopub.execute_input":"2025-04-19T16:06:51.417495Z","iopub.status.idle":"2025-04-19T16:06:51.421543Z","shell.execute_reply.started":"2025-04-19T16:06:51.417471Z","shell.execute_reply":"2025-04-19T16:06:51.420859Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Get test loader\ndef get_test_loader(batch_size):\n    transform = get_transforms(data_augmentation=False)\n    test_dataset = ImageFolder(\"/kaggle/input/inaturalist_12K/val\", transform=transform)\n\n    num_workers = min(os.cpu_count(), 4) if torch.cuda.is_available() else 0\n    pin_memory = torch.cuda.is_available()\n\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,num_workers=num_workers, pin_memory=pin_memory)\n    return test_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:06:51.769661Z","iopub.execute_input":"2025-04-19T16:06:51.770215Z","iopub.status.idle":"2025-04-19T16:06:51.774587Z","shell.execute_reply.started":"2025-04-19T16:06:51.770191Z","shell.execute_reply":"2025-04-19T16:06:51.773773Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def train_best_model():\n    # Get activation function\n    activation_fn = get_activation_fn(bestConfig['activationFn'])\n\n    # Initialize model\n    model = SimpleCNN(\n        convFilters=bestConfig['convFilters'],\n        filterSizes=bestConfig['filterSizes'],\n        activationFn=activation_fn,\n        useBatchNorm=bestConfig['useBatchNorm'],\n        dropoutRate=bestConfig['dropoutRate'],\n        optimizerType=bestConfig['optimizerType'],\n        learningRate=bestConfig['learningRate'],\n        weightDecay=bestConfig['weightDecay'],\n        denseFeatures=bestConfig['denseFeatures'],\n        numClasses=bestConfig['numClasses']\n    )\n\n    # Load Data (no augmentation for val/test)\n    train_loader, val_loader = load_data(\n        batch_size=bestConfig['batchSize'],\n        data_augmentation=bestConfig['dataAugmentation']\n    )\n\n    # Trainer\n    trainer = pl.Trainer(\n        precision='16-mixed',\n        max_epochs=10,\n        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n        devices=torch.cuda.device_count() if torch.cuda.is_available() else 1,)\n\n    # Train and validate the model\n    trainer.fit(model, train_loader, val_loader)\n    val_metrics = trainer.validate(model, dataloaders=val_loader, verbose=True)\n\n    return model,val_metrics,trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:23:02.152658Z","iopub.execute_input":"2025-04-19T16:23:02.153178Z","iopub.status.idle":"2025-04-19T16:23:02.158942Z","shell.execute_reply.started":"2025-04-19T16:23:02.153156Z","shell.execute_reply":"2025-04-19T16:23:02.158039Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"model, val_metrics, trainer = train_best_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T16:23:05.610032Z","iopub.execute_input":"2025-04-19T16:23:05.610306Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/parsing.py:45: Attribute 'activationFn' removed from hparams because it cannot be pickled. You can suppress this warning by setting `self.save_hyperparameters(ignore=['activationFn'])`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d7d9f99e94a4e98a862500aa6d6b6fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a5b3c2951fd413f8bbf5cd03c556cb4"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# Now use trainer to evaluate on test set\ntest_loader = get_test_loader(batch_size=bestConfig['batchSize'])\ntest_metrics = trainer.test(model, dataloaders=test_loader, verbose=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_predictions_grid(model, test_loader, device, class_names=None):\n    model.eval()\n    model.to(device)\n\n    images_to_show = 30  # Total number of imgs to display\n    shown = 0            # Variable to store number of images displayed\n\n    # Create a 10x3 subplot grid to show 30 images\n    fig, axs = plt.subplots(10, 3, figsize=(13, 26))\n    axs = axs.flatten()  # Flatten the 2D array of axes for easy indexing\n\n    with torch.no_grad():  # No gradient calculation needed during evaluation\n        for batch in test_loader:\n            images, labels = batch\n            images = images.to(device)\n\n            # Getting model predictions\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1)\n\n            # Moving tensors to CPU for visualization\n            images = images.cpu()\n            labels = labels.cpu()\n\n            for i in range(images.shape[0]):\n                if shown == images_to_show:\n                    break \n\n                # Converting single image tensor to a displayable numpy image\n                img = torchvision.utils.make_grid(images[i])\n                img = img.permute(1, 2, 0).numpy()\n\n                axs[shown].imshow(img)  # Show the image\n\n                pred_label = class_names[preds[i]] if class_names else f\"{preds[i].item()}\"\n                true_label = class_names[labels[i]] if class_names else f\"{labels[i].item()}\"\n\n                # Color-code the title: green for correct, red for incorrect\n                correct = preds[i] == labels[i]\n                color = 'green' if correct else 'red'\n\n                # Set image title with prediction and ground truth\n                axs[shown].set_title(\n                    f\"Pred: {pred_label}\\nTrue: {true_label}\",\n                    fontsize=10,\n                    color=color\n                )\n                axs[shown].axis('off') \n                shown += 1\n\n            if shown == images_to_show:\n                break \n\n    fig.suptitle(\"Test Predictions Grid (Green = Correct, Red = Wrong)\", fontsize=16, y=1.02)\n    plt.tight_layout()\n\n    # Save the figure to a buffer (in memory) for logging to Wandb\n    buf = BytesIO()\n    plt.savefig(buf, format='png', bbox_inches='tight')\n    buf.seek(0)\n\n    # Log the image to Wandb\n    wandb.init(project=\"da6401_Assignment2\")\n    wandb.log({\"Creative Test Grid (10×3)\": wandb.Image(buf, caption=\"Color-coded 10×3 Grid\")})\n    wandb.finish()\n\n    # Show the grid locally (useful in notebook or script)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def visualize_first_layer_filters(model: nn.Module) -> None:\n#     \"\"\"\n#     Plot all first-layer Conv2d filters in square grid.\n#     \"\"\"\n#     conv = model.convBlocks[0][0]\n#     weights = conv.weight.data.cpu()\n#     n = weights.shape[0]\n#     grid = int(n**0.5)\n\n#     fig, axs = plt.subplots(grid, grid,\n#                              figsize=(grid, grid))\n#     for i in range(n):\n#         w = weights[i]\n#         w = (w - w.min()) / (w.max() - w.min())\n#         ax = axs.flatten()[i]\n#         ax.imshow(w.permute(1,2,0))\n#         ax.axis('off')\n#     plt.suptitle(\"First-Layer Filters\")\n#     plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# class GuidedBackprop:\n#     \"\"\"Guided backpropagation utility.\"\"\"\n#     def __init__(self, model: nn.Module):\n#         self.model = model\n#         for m in self.model.modules():\n#             if isinstance(m, nn.ReLU):\n#                 m.register_backward_hook(self._hook)\n\n#     def _hook(self, module, grad_in, grad_out):\n#         return (torch.clamp(grad_in[0], min=0.0),)\n\n#     def generate(self, img: torch.Tensor, layer_idx: int,\n#                  neuron_idx: int) -> torch.Tensor:\n#         inp = img.clone().requires_grad_(True)\n#         out = inp\n#         for block in self.model.convBlocks[:layer_idx+1]:\n#             out = block(out)\n#         loss = out[0, neuron_idx].mean()\n#         self.model.zero_grad()\n#         loss.backward()\n#         return inp.grad[0].cpu()\n\n\n# def plot_guided_backprop(model: nn.Module, dataset,\n#                           device: torch.device,\n#                           layer_idx: int = 4,\n#                           num_neurons: int = 10) -> None:\n#     \"\"\"\n#     Plot guided backprop saliency maps for random neurons.\n#     \"\"\"\n#     gb = GuidedBackprop(model)\n#     img, _ = dataset[random.randint(0, len(dataset)-1)]\n#     inp = img.unsqueeze(0).to(device)\n\n#     channels = model.convBlocks[layer_idx][0].out_channels\n#     neurons = random.sample(range(channels), num_neurons)\n\n#     fig, axs = plt.subplots(1, num_neurons,\n#                              figsize=(num_neurons*2, 2))\n#     for ax, n in zip(axs, neurons):\n#         grad = gb.generate(inp, layer_idx, n)\n#         ax.imshow(grad.permute(1,2,0).mean(2), cmap='viridis')\n#         ax.set_title(f\"N{n}\")\n#         ax.axis('off')\n#     plt.suptitle(f\"Guided Backprop on Conv{layer_idx+1} Neurons\")\n#     plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Load train/val and test data\n# train_loader, val_loader = load_data(BATCH_SIZE)\n# test_loader = get_test_loader(TEST_DIR, BATCH_SIZE)\n# test_dataset = test_loader.dataset\n\n# # Build model architecture with best hyperparameters\n# activation_fn = get_activation_fn(HPARAMS['activationFn'])\n# model = SimpleCNN(\n#     convFilters=HPARAMS['convFilters'],\n#     filterSizes=HPARAMS['filterSizes'],\n#     activationFn=activation_fn,\n#     useBatchNorm=HPARAMS['useBatchNorm'],\n#     dropoutRate=HPARAMS['dropoutRate'],\n#     optimizerType=HPARAMS['optimizerType'],\n#     learningRate=HPARAMS['learningRate'],\n#     weightDecay=HPARAMS['weightDecay'],\n#     denseFeatures=HPARAMS['denseFeatures'],\n#     numClasses=HPARAMS['numClasses']\n# )\n# model.to(DEVICE)\n\n# # Train on train+val with Lightning\n# trainer = pl.Trainer(\n#     max_epochs=MAX_EPOCHS,\n#     gpus=1 if torch.cuda.is_available() else 0\n# )\n# trainer.fit(model, train_loader, val_loader)\n\n# # Evaluate and visualize\n# evaluate_model(model, test_loader, DEVICE)\n# plot_predictions(model, test_dataset, test_dataset.class_names, DEVICE)\n# visualize_first_layer_filters(model)\n# plot_guided_backprop(model, test_dataset, DEVICE)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}